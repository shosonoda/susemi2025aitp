了解しました。2000年代以降の機械学習を用いた定理自動証明のタスク、システム、およびアルゴリズムについて調査し、論文ごとに概要をまとめたレポートを作成します。

- 2000年代以降の主なアプローチや技術
- 主要な定理自動証明のサブタスク（premise selection, proof step generation 以外にも伝統的に扱われているもの）
- 代表的なシステムやツール（HOL(y)Hammer, CoqHammer, MaSh, TacticToe, Tactician, ML4PG, SEPIA, Gamepad, CoqGym, MaLARea, DeepMath 以外に存在するものも含める）
- 伝統的な統計手法、強化学習、ニューラルネットを用いた手法も含める
- 2000年代以前の先駆的な研究も別項目としてまとめる

調査が完了次第、レポートを共有いたします。

**概要**  2000年代以降、機械学習（ML）は定理自動証明におけるさまざまな課題に活用され、大規模定理ライブラリの活用や証明探索の自動化を飛躍的に進展させました。本調査では、(1) **主要なアプローチと技術**（各サブタスクとML手法）、(2) **代表的システムとツール**（特徴・技術・適用範囲の比較）、(3) **2000年代以前の先駆的研究**の観点から整理し、最後に主要論文の概要と比較表を示します。

## 1. 主要なアプローチと技術

### 1.1 前提選択（Premise Selection）
**定義**: 膨大な定理の記録から、与えられたゴールの証明に有用な前提（既知定理・補題）を自動抽出するタスク。定理証明支援系や自動定理証明でボトルネックとなる課題です[Li2024theoremprovingsurvey]()。

**従来手法**: 2000年代以降、まず統計的学習が導入されました。ヒューリスティクスによる絞り込み（例：SInEアルゴリズム）に加え、**Naive Bayes**や**k-近傍法**による分類器で「定理と前提の関連性」を学習する手法が登場しました[Gauthier2018thesis]()。たとえばBlanchetteらはIsabelle/Sledgehammer向けに **MaSh** を開発し、証明から抽出したシンボル列や項構造の特徴に基づくNaive Bayes分類器とk-NNを組み合わせて有用な前提を予測しました 。これらはMizarやHOL Lightの大規模定理集（Flyspeckプロジェクトなど）を訓練データに、従来の手工的特徴では困難だった関連性を統計的に捉え、前提選択の精度を向上させました。

**深層学習の導入**: 2010年代半ばからは**ディープラーニング**による前提選択が本格化しました。**DeepMath** (2016) [Irving2016deepmath]() は「定理と各候補前提が関連するか」をバイナリ分類するモデルで、論理式をトークン列にエンコードしCNNやRNNでベクトル表現に変換、最終層で関連性スコアを出力しました。**HolStep** (2017) [kaliszyk2017holstep]() もHOL Light定理アーカイブを用いた大規模ベンチマークで、LSTMなどによる類似手法を評価しています。その後、**WaveNet**風のモデルやTransformerを組み込んだ改良（Kucik and Korovin, 2018, Szegedy et al., 2021）も登場し、手作りの特徴設計に頼らないエンドツーエンド学習で精度向上が報告されています。さらに論理式の構造を活かすため **グラフニューラルネット(GNN)** が活用され、論理項を木やグラフ構造（項の構文木や項間依存グラフ）に変換して学習する流れも盛んです。例えば **FormulaNet** [Wang2017formulanet]()）は論理式を節点・辺からなる有向グラフに表現し、エッジ順序の情報も保持した埋め込み手法を提案しました。[Olsak2020gnn](https://ecai2020.eu/papers/1259_paper.pdf)は論理項の対称性など**論理的不変性**を保つGNNフレームワークを導入し、[Paliwal2020]()はHOL Lightでグラフ表現の詳細な比較実験を行っています。近年は**対照学習**でグラフ表現を洗練する試みや、大規模定理依存グラフ全体を構築して**リンク予測**（ノード間エッジの有無予測）問題に帰着する手法も現れました。また、**事前学習言語モデル**の応用として、定理を自然文風に記述してBERT系列モデルでベクトル化し、線形分類器で前提選択するアプローチも検討されています（[Ferreira2020premise]() [Welleck2022]()）。

### 1.2 証明ステップ生成と強化学習
**定義**: 証明の各ステップ（論証展開や戦略）を自動で生成・選択するタスクです。とくにITPでは「次に適用すべきタクティック（戦略コマンド）を予測するタスク」に相当し、ATPでは「推論ルールの適用や解探索のガイド」に相当します。

**タクティック予測（分類型）**: 証明過程を大規模な逐次データとみなし、あるゴール状態における最適なタクティックと引数を推薦・適用するものです。**GamePad** (2018) [huang2018gamepad]() はCoqにおける人間の証明軌跡を「状態–アクション」対のデータと見立て、Tree-LSTMでゴール状態をベクトル化し、タクティックの種類とその引数をそれぞれ別の分類器で予測しました。**Proverbot9001** [Sanchez-Stern2020Proverbot9001]() はLeanの証明データを用い、フィードフォワードNNでタクティックを、RNNで引数を予測するモデルを構築しています。これらはタクティック適用を**多クラス分類**問題に分解した手法で、既存の定理庫での人間証明を教師データに高い精度で次手を当てることができました。一方、**ASTactic** [Yang2019astactic]() はタクティックと引数を逐次生成する**シーケンスデコーダ**型モデルで、あらかじめ定めた文法に沿ってRNNがタクティックスクリプト全体を生成します。ASTactic系列の手法はその後、過去の証明スクリプトを条件に加える工夫（[First2020–2022]()）やモデル種類の組合せ、定理名（識別子）の埋め込み考慮（[Sanchez-Stern2023]()）などで精度が改善されています。

**言語モデル（生成型）**: 近年、タクティック予測を「条件付き言語生成」とみなすアプローチが飛躍的に発展しています。OpenAIの **GPT-f** (Polu & Sutskever, 2020) はTransformerベースの生成モデル（GPT系）をMetamath言語の定理証明に適用し、ゴールと既知事実を入力すると次の証明ステップをテキスト生成する形式で学習しました。具体的には「`GOAL <ゴール表現> PROOFSTEP <ステップ表現>`」というペア列を生成する訓練を行い、高精度の次ステップ提案を実現しました。このモデルはMetamathライブラリの定理の56.5%を自動証明したと報告されています。さらに **Baldur** [First2023baldur]()はTransformerで証明全体を一括生成・修正するアプローチを試みています。また、タクティック予測と前提選択を**統合的に学習**する研究も活発です。**NaturalProver** [Welleck2022]()は巨大言語モデルGPT-3を微調整し、事前に検索した関連定理（前提）を活用して整合性の高い証明文を生成しました。**Thor** [Jiang2022thor]() は生成中に特殊トークン `<hammer>`（ハンマー）を出力させ、そこに至ったサブゴールは外部ATPで自動解決するよう設計しています。これらの手法により、大規模言語モデルを用いた証明ステップ自動生成が飛躍的に高精度化しつつあります。

**強化学習**: 証明探索をゲームとみなし、強化学習(RL)で最適戦略を学習する試みも行われています。DeepMindの **HOList** 環境 (Bansalら, 2019) はHOL LightをRLのプラットフォームとして整備し、ディープ強化学習エージェント **DeepHOL** を用いて定理証明を試みました。DeepHOLは自己対戦によるモンテカルロ木探索(MCTS)と方策勾配法で戦略を最適化し、Flyspeck由来の定理群で有望な結果を示しています。同様に、Gauthierら(2018)の **TacticToe** はHOL4でのタクティック探索をA*-探索と統計的学習でガイドし、既知の戦略パターンから最適な手順を選択することでHOL(y)Hammerを上回る再現定理数を達成しました。このように、強化学習を組み合わせることで未知の難問に対する自動証明能力を高めるアプローチも着実に進展しています。

### 1.3 その他のタスク
- **戦略選択・パラメータ自動調整**: 一階述語論理のATPでは、与えられた問題に対して最適な推論戦略やパラメータを選ぶことも重要です。[Bridge2014fol]()は問題の特徴量（公理数や項構造の統計など）から推論ヒューリスティックを選択する分類器を学習し、Vampire等のプロバーで単一の固定戦略を上回る性能を示しました 。この手法では53種類のヒューリスティックそれぞれに分類器を訓練し、新規問題では最適と思われる戦略を自動適用します。同様のアイデアで、問題毎にATPやそのオプション設定を切り替えるポートフォリオ手法も研究されています（SATソルバにおけるSATzillaの定理証明版など）。

- **証明状態評価**: GamePad [huang2018gamepad]() では「現在の部分証明が完了まであと何ステップか」を予測する**ポジション評価**タスクを設定し、学習モデルに証明探索の優先度付けをさせる試みをしています。これにより、「ゴール達成まで遠い状態」を検知して探索を効率化するなど、チェスプログラムの局面評価に似たアプローチで証明検索を賢く制御できます。

- **補題発見・証明分割**: 大規模証明では中間補題の自動発見も鍵となります。近年、証明生成AIに中間ゴールを自律的に提案させる研究（例：[Liang2019]()の強化学習による補題生成）が始まっています。また、大型言語モデルに非形式的証明から形式的補助定理を抽出させる試み（[Wu2022]()）もあり、今後の発展が期待されます。

## 2. 代表的なシステムとツール

ここでは機械学習を組み込んだ主な定理証明支援システムを列挙し、その特徴を比較します。

- **HOL(y)Hammer**: HOL Light向けのハンマー（ATP連携）システムです。定理を一階論理に翻訳しEやVampireなどATPで証明探索する前に、大規模ライブラリ（HOL Light標準ライブラリやFlyspeck）から有望な前提を機械学習で選択します。k-NNやNaive Bayesによる前提選択器を備え、外部ATPが発見した証明をHOL Lightに再構築します。大規模定理集で約40%超の定理を自動証明する性能を示しました。HOL(y)HammerはHOL4やIsabelle/Mizar向けにも派生版が作られ、**汎用的なハンマー手法の先駆け**となっています。

- **CoqHammer**: Coq向けのハンマーです。HOL(y)Hammerの手法をCoqの直観主義論理や依存型に対応させた点が特徴で、Coqの定理を一階論理へ翻訳する際の情報損失を補う工夫があります。前提選択には統計的MLを用い、外部ATP（E等）での証明探索とCoq内での証明再構成を統合しています。Coqの大規模ライブラリ（MathCompなど）でも数多くの定理を自動証明できるようになり、Coqにおける自動化の実用性を飛躍させました。

- **MaLARea (Machine Learning Assisted Automated Reasoning)**: Mizarを対象に、ATPと学習をループで組み合わせた画期的システムです。初期はシンボル共起に基づく簡易推定で前提集合を選びATPで証明、得られた新定理を追加学習して次の問題に臨むという **自己強化ループ** を実装しました。MaLAReaは難易度の高いMizar定理も次々解決し、当時のCASC Large Theoryカテゴリーで優勝する成果を収めています。のちのハンマー系統の発想源ともなりました。

- **Sledgehammer + MaSh**: [Kuhlwein2013mash]() Isabelle/HOLの自動補題選択ツールSledgehammerに、機械学習による前提選択を統合したものです。MePo [Meng2009mepo]()（単純なシンボルマッチングベース）に代えて、MaShを導入しNaive Bayesとk-NNで証明依存関係から前提をランキングします。この結果Isabelleでも外部ATP連携が安定し、大規模開発での自動化率が向上しました。MaShはIsabelle以外（Leanなど）にも比較的容易に移植可能であることが示されています。

- **TacticToe**: HOL4向けのタクティックベース自動証明器です。HOL(y)Hammerとは異なり高階論理上で直接動作し、証明をタクティック列として構築します。**A*検索**と機械学習によるガイドを組み合わせ、既存の膨大なHOL4証明から各ゴールで有効なタクティックを予測します。前提も必要に応じ選択しつつ探索するため、タクティックと前提選択の二重の学習を活用しています。短時間でHOL4定理アーカイブの39%を再証明し、同条件でのHOL(y)Hammer (32%)を上回る性能を示しました。タクティック主導の新アプローチとして注目されました。

- **Tactician**: Coq向けのタクティック学習プラグインです。ユーザが証明スクリプトを書く際に、その履歴をオンライン学習し、次の一手をインタラクティブに支援します。また自動モードではユーザの介入なしに学習済み知識で証明探索も可能です。特徴はCoq開発環境へのシームレスな統合で、Opamパッケージとしてプロジェクト依存関係も含め学習し活用できます。内部にはk-NNベースのシンプルモデルから、Graph2Tacなど深層学習モデルまで複数実装を切替可能で、最新バージョンではCoqの定理自動証明で26%という最先端の成功率を達成しています。

- **GamePad**: CoqをPythonインタフェース経由で操作し、学習用の環境・データセットを提供するプラットフォームです。Coqの証明過程を「ゲーム」と捉え、状態（ゴールとコンテキスト）と合法手（タクティック適用）の遷移をデータとして収集・学習できます。GamePad論文では(1)残り証明ステップ数の予測、(2)次のタクティック予測という2つのベースラインタスクを設定し、Feit-Thompsonの大定理の一部を含むデータでモデルを訓練しています。その結果、証明状態から適切なタクティックを当てるモデルを構築できることを示し、今後の強化学習や大規模学習の土台となりました。

- **CoqGym**: 大規模なCoq証明データセットおよび学習環境です。Coqの定理12,000件以上からタクティック列を抽出し、機械学習用に前処理したデータセットCoqGymを公開しました。論文ではASTacticモデルを提案し、このデータセットで学習・評価を実施しています。Coqに対する深層学習研究が大きく促進されました。

- **DeepMath**: [Irving2016deepmath]() は前述のDeepMathモデルを指し、大規模定理選択に深層学習を初適用した成果です。

- **HOList**: [Bansal2019holist]() HOL Lightベースの学習環境と、強化学習エージェントDeepHOLを開発しました。

- **ENIGMA** [Jakubuv2017enigma]() は一階ATP Eプロバーに統合された学習ガイドで、充足不能集合から得られる「有用な補題（ヒント）」を特徴ベクトル化し、勾配ブースティング木やNNで有望な論理項を選択します。ENIGMAはVampireにも取り入れられ、従来の手作り戦略では解けなかった問題の解決に成功しています。  

以上の他にも、**SEPIA** [Gransden2015sepia]() Coqの証明系列から有限オートマトンを学習して探索、**ML4PG** [Heras2013ml4pg]() Coq証明をクラスタリングして類似パターンを発見など、機械学習を活用したユニークなシステムが多数存在します。

各システムの技術的特徴をまとめると以下の通りです：

| システム           | 対象   | 主な技術                     | 特徴・備考 |
|--------------------|--------|------------------------------|----------------------------------------|
| HOL(y)Hammer       | HOL系 (HOL Light/HOL4) | 前提選択(統計ML)、ATP連携| 最初期のハンマー。HOL4版も開発。 |
| CoqHammer          | Coq    | 前提選択(統計ML)、ATP連携    | Coqの論理に対応。MathComp対応。 |
| Sledgehammer + MaSh| Isabelle/HOL | 前提選択(統計ML：NB+kNN)    | Isabelleのハンマー。学習による自動化率向上。  |
| MaLARea            | Mizar  | 前提選択+反復学習ループ      | 学習とATPを統合し大規模定理証明。 |
| TacticToe          | HOL4   | タクティック予測(A*探索+学習)| タクティック列自動構成。性能向上顕著。 |
| Tactician          | Coq    | タクティック予測(オンライン学習) | Coqに統合、対話的支援と自動証明。 |
| GamePad            | Coq    | 学習環境（Python API）       | Coqをゲーム化、データ収集。    |
| CoqGym             | Coq    | 学習データセット・環境       | 大規模Coqデータ、ASTactic提案。 |
| DeepMath           | Mizar  | 前提選択(深層学習)           | 初の大規模DL適用。            |
| HOList + DeepHOL   | HOL Light | 強化学習(MCTS+NN)、前提選択(DL)| RLで定理証明。ベンチマーク提供。 |
| ENIGMA             | 一階ATP(E) | 帰結選択(勾配Boosting/NN)    | プルーフヒント学習、ATP内蔵。難問解決を実現。 |

## 3. 2000年代以前の先駆的研究

機械学習と定理証明の融合は1990年代から萌芽的に試みられていました。当時は計算資源やデータ不足もあり小規模な研究に留まりましたが、後の発展に影響を与えています ([](https://www.nowpublishers.com/article/DownloadSummary/MAL-081#:~:text=et%20al,This%20review))。

- **MULTIPLE** [Slagle1965multiple]() [Slagle](https://www.chessprogramming.org/James_R._Slagle) ([The birth of Artificial Intelligence (AI) research | Science and Technology](https://st.llnl.gov/news/look-back/birth-artificial-intelligence-ai-research)): 非常に早期の試みとして、SlagleのMULTIPLEは「学習する定理証明プログラム」を目指したもので、幾何やチェッカーゲームまで含め「次に何をすべきか」を学習によって柔軟に決定するコンセプトを提案しました。これは定理証明を含む広範な問題でヒューリスティックを自動調整する先駆例でした。

- **1980年代の学習型ATP**: 1980年代後半にはニューラルネットによる証明探索指針の学習が試みられました。[Ertel1989]() [Suttner1990]() はバックプロパゲーションを用いて定理証明プログラムのヒューリスティックを調整し、検索空間を削減する実験を行いました。これらは小規模な問題で有望性を示しました。また [Denzinger1999]() は分散協調型の定理証明で、並行するプロバー同士が解探索の経験（有効な中間結果）を共有・学習する仕組みを研究し、チームワークによる効率向上を報告しています。

- **説明ベース学習 (EBL)**: 1990年代には計画問題におけるEBL技術 [Ellman1989ebl]() が定理証明にも応用され、既知の証明例から不要な探索を避けるルールを学ぶ研究も行われました。例えば証明失敗例の解析から補助定理の必要性を学習するなど、人手の経験知を機械に獲得させる試みがなされました。

- **ヒント戦略** [Veroff2001](): Otterにおいて、一度得られた証明から主要補題を抽出しヒントとして蓄積し、類似問題の探索を加速する手法を開発しました。これは統計的学習ではないものの、「過去の証明知識を再利用する」という発想であり、MaLAReaやENIGMAの「証明から学習する」路線に通じるものです。

これら先駆的研究は規模や精度の点で限定的でしたが、「探索戦略を自動で最適化する」「過去の知見を蓄積して新たな証明に活かす」という発想を提示し、2000年代以降のML×定理証明研究の土台となりました。

## 4. 主要論文の概要

最後に、本調査で言及した主要な研究論文を年代順にまとめ、その概要を記します。

- **Alama et al. (2014)** – [Alama2014]() *Premise Selection for Mathematics*: Mizarの定理集を対象にNaive Bayes分類による前提選択を実装した先駆的研究。定理と前提間の依存関係から特徴ベクトルを構成し、ベイズ推定で有用度の高い補題をランキング。大規模実験により、人手選択より良好な結果を示した。

- **Bridge et al. (2014)** – [Bridge2014fol]() *Machine Learning for First-Order Theorem Proving: Learning to Select a Good Heuristic*: 一階述語ATPの複数の探索戦略から問題毎に最適なものを選択する学習手法を提案。53種のヒューリスティックを用意し、問題の特徴から最速で解ける戦略を分類器が予測。実験で単一戦略を上回る成功率を達成し、戦略ポートフォリオにMLを導入する可能性を示した。

- **Irving et al. (2016)** – *DeepMath: Deep Sequence Models for Premise Selection*: 初めて深層学習（LSTM等）を大規模定理選択に適用。Mizar40コーパスで定理・前提ペアを学習し、従来のk-NNやSVMベース手法に匹敵する精度を実現。大規模数学定理にもDLが有効であることを示した。

- **Kaliszyk et al. (2017)** – *HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving*: HOL Lightの定理9414件を含むデータセットHolStepを構築し、CNNや強化学習エージェントを評価。前提選択と次の証明ステップあてクイズ形式のタスクを設定し、多様なモデル比較を行った。以後のHOL系学習研究の標準ベンチマークとなった。

- **Gauthier et al. (2017)** – *TacticToe: Learning to Reason with HOL4 Tactics*: 前述のTacticToe手法を提案。HOL4の定理7164本中66.4%を60秒で自動証明し、HOL(y)Hammerや既存戦略を凌駕。タクティック列探索+A*+学習という新方式の有効性を示し、他のITPにも影響を与えた。

- **Bansal et al. (2019)** – *HOList: An Environment for Machine Learning of HOL Theorem Proving*: DeepMindによるHOL Lightベースの学習環境提供。強化学習エージェントによる定理証明(DeepHOL)で初期成果を報告し、データセットと環境をオープンソース公開。機械学習研究者が定理証明アルゴリズムを試せるプラットフォームとなった。

- **Huang et al. (2019)** – *GamePad: A Learning Environment for Theorem Proving*: Coqを用いた学習環境とベースラインモデルの提案。タクティック予測と残りステップ数予測でニューラルネットを訓練し、Feit-Thompson定理の一部を自動合成。人間の手による大定理証明を機械学習で再現する一歩を示した。

- **Yang & Deng (2019)** – *Learning to Prove Theorems via Interacting with Proof Assistants (CoqGym)*: CoqGymデータセットとASTacticモデルを提案。12KのCoq証明を収集し、Seq2Seqモデルで戦略を生成。大規模データで学習したモデルが既存定理の40%以上を自動証明できることを報告し、以後のCoqにおける学習研究の基盤を築いた。

- **Polu & Sutskever (2020)** – *GPT-f: Generative Language Modeling for ATP*: GPT-3相当のTransformerをMetamath定理証明に応用し、与えられたゴールから証明を逐語的に生成する手法を提案。自己回帰言語モデルを条件付き確率最大化で学習し、Metamath定理の56.5%を自動証明。大規模言語モデルの定理証明応用可能性を示したブレイクスルー。

- **Welleck et al. (2022)** – *NaturalProofs/NaturalProver*: 自然言語と定理証明の橋渡しを目指し、巨大言語モデルに数学定理の文章と形式証明を学習させた研究。特にNaturalProverでは、まず関連する定理文を検索で取得し、それらを引用しながらGPT系モデルに証明文を出力させる。これにより従来困難だった長手の形式証明生成に成功しつつある。

- **First et al. (2023)** – *Baldur: Whole Proof Generation*: 証明全体を一括生成・修正する新手法を提案。GPTモデルにより一度に証明全体を出力し、検証失敗箇所をモデルが部分修正するループで完成度を高める。大規模データで学習することで、人間の証明スタイルに近い全体最適な証明構築を目指す。

以上のように、機械学習を用いた定理自動証明は多彩な方向で進展しています。大規模データとディープラーニングにより近年著しい成果が上がっており、定理証明分野に新たな自動化ブレイクスルーをもたらしつつあります。
