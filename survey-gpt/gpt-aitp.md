<!-- 了解しました。数学・論理・機械学習に精通した読者向けに、AIにおける自動証明の歴史的背景、現在の主流手法、技術的比較、および今後の展望について詳述したコラムを執筆します。

特に以下の点を重視します。
- Reinforcement learning from human feedback、supervised-fine tuning (SFT)、Bradley-Terry model、direct preference optimization、process reward model、group relative policy optimization、MonteCarlo tree search などの機械学習手法の整理。
- ChatGPTシリーズ、GPT-f、Claude、Gemini、PaLM (Minerva)、Llama、Llemma、MathShepherd、DeepSeekシリーズ (DeepSeek Prover V1.5, DeepSeek V3)、Qwenシリーズ (Qwen2.5)、rStar-Math、Lean-star、STP、Goedel-Prover、ProofWiki、Thor、Draft Sketch and Prove、HyperTree Proof Search、LeanDojo などの主要な研究の比較。
- miniF2F、ProofNet、Putnamなどのベンチマークデータセットの整理。
- 技術的な背景に基づく性能や性質の違いの分析（スケール、補助ツールの統合、探索アルゴリズムの違いなど）。
- 主要な研究やベンチマークの比較を表にまとめる。

執筆完了後、お知らせします。 -->

# 数学AIにおける自動証明の進化と展望

## はじめに
人工知能による **自動定理証明（Automated Theorem Proving, ATP）** は、数学や論理の問題をコンピュータが自動で証明することを目指す分野です。1950年代にNewellらの Logic Theorist などが黎明期を築き、1960年代にはRobinsonの導出原理による論理推論が確立しました。しかし、純粋に記号的な手法だけでは、人間のように創造的な洞察を要する複雑な証明や、大規模な探索空間を効率よくナビゲートすることが難しいという限界も早くから指摘されていました。

21世紀に入り、機械学習、とりわけ**深層学習**の発展により、自動証明にも新たなアプローチが持ち込まれました。大規模言語モデル(LLM)を数学問題に適用する試みや、強化学習を用いて証明探索を行う研究が次々と登場しています。近年はGPT-4やClaudeといった汎用LLMが高度な数学問題に人間並みの推論力を示し、GPT-fのように証明支援系（Metamath）にLLMを応用して新しい証明を発見する例も現れました([GPT-f]())。本稿では、こうした自動証明AIの歴史的背景から最新の手法までを整理し、技術的観点での比較と今後の展望を述べます。特に、**機械学習を用いた主要手法**や、**代表的なシステム/モデル**の特徴とベンチマーク性能を比較します。

## 自動定理証明の歴史的背景
自動定理証明の研究は計算機科学の黎明期から存在し、初期は論理式の**形式操作**による証明探索が中心でした。1950年代のLogic TheoristはWhitehead and Russellの『プリンキピア・マテマティカ』の定理を証明し、AIにおける推論システムの可能性を示しました。1965年にはJ. Robinsonによる**一階述語論理の導出原理**が登場し、論理推論をコンピュータで自動化する基盤が整いました。これらは証明支援系（IsabelleやHOLなど）の原型となり、1980–90年代には人手で定義した**推論規則**と**検索アルゴリズム**を組み合わせた自動定理証明器（例えばOtterやE）が発達しました。

しかし、複雑な数学問題では証明探索空間が爆発的に大きくなり、従来の**ヒューリスティック**では太刀打ちできません。そこで2000年代以降は、証明支援系（Coq、Isabelle、Leanなど）で**対話的定理証明**が主流となります。これは人間が戦略や補題を提示し、コンピュータは機械的部分を検証するシステムです。自動証明は限定的な補題証明に留まっていました。

転機は2010年代後半から訪れました。ディープラーニングにより画像認識やゲームAIが飛躍的進歩を遂げたことを受け、**数学分野へのディープラーニング応用**が注目されたのです。2016年のAlphaGoに始まる強化学習＋モンテカルロ木探索（MCTS）の成功は、組合せ的探索問題としての定理証明にも適用可能ではないかと期待されました。実際、2018年前後にはまず**補題選択（premise selection）**への機械学習導入（与えられた定理に有用な過去の定理をランク付けするなど）が行われ、そして2019年以降は**Transformer型の言語モデル**による定理証明ステップ生成が試みられるようになります。Open AIのGPT-f (2020) はその先駆けで、Metamathという形式体系でTransformerが新たな証明を生成し、それが実際に定理ライブラリに採択されました([GPT-f]())。またMetaのHyperTree Proof Search(2022)はAlphaZero流のMCTSでLeanやMetamathの定理証明性能を大きく向上させています ([HTPS]())。2022年にはGoogleが**Minerva**（PaLMを数理領域に特化調整したモデル）を発表し、文章形式の数学問題で当時最高性能（数学コンペ問題MATHで50%正答）を達成しました。以降、大規模モデルと強化学習を組み合わせたアプローチが続々と登場し、現在に至っています。

## 自動証明における機械学習手法の整理
### 教師ありファインチューニング (SFT)
まず基盤となるのが **教師ありファインチューニング (Supervised Fine-Tuning)** です。大規模言語モデルを証明タスク向けに特化させるため、既存の証明データ（人間の書いた証明や証明支援系のタクティク列など）でモデルを微調整（fine-tune）します。例えばGPT-fでは、Metamathの膨大な形式証明データでGPT-3をファインチューニングし、文法的に正しい証明文を生成できるようにしました。DeepSeek-Proverでもまず DeepSeekMath-Base という事前学習モデルを用意し、そこに蓄積された定理証明データを教師あり学習しています([DS-Prover]())。SFTはモデルに基本的な**論理推論パターン**や**定理ライブラリの知識**を与えるステップであり、この段階での性能がその後の強化学習の効果を左右します。

### 人間のフィードバックを用いた強化学習 (RLHF) とその拡張
ChatGPTの成功で知られる**Reinforcement Learning from Human Feedback (RLHF)**は、モデルの出力に対する人間からの**好ましさ**評価を報酬としてモデルを調整（alignment）する手法です。証明生成においても、例えば「証明が論理的に一貫しているか」「読みやすいか」など、人間が好む性質を学習させる目的でRLHFが考えられます。しかし数学証明では評価の客観性が問題で、単純な良し悪しのラベル付けは困難です。そのため、RLHFの代替や拡張として以下のような手法が登場しています。

- **Bradley-Terryモデルによる報酬学習**: 人間が複数の出力を比較して「どちらが好ましいか」を選ぶデータから、**報酬モデル**を学習する際に使われる手法です。Bradley-Terryモデルは勝敗データから各選手のスコアを推定するモデルで、RLHFでは2つの回答A,Bについて「Aが好ましい」とされたら $P(A \succ B) = \sigma(r_A - r_B)$ となるよう内部スコア$r$を調整します。この手法でInstructGPTでは人間の嗜好をモデル化する報酬関数を学習しました([InstructGPT]())。

- **直接的嗜好最適化 (DPO)**: これは**強化学習を明示的に行わずに**人間の嗜好にモデルを合わせ込む新手法です ([DPO]())。従来RLHFでは、報酬モデルから得た報酬を最大化するようPPOなどでポリシーを更新していましたが、DPOでは**対数確率の差**で直接損失関数を構成し、勾配法でモデルを調整します。これにより**KLペナルティの調整**など煩雑な要素を省き、安定した学習ができると報告されています。大規模言語モデルの嗜好適応で注目されており、``RLHF without RL'' とも呼ばれます。

- **プロセス報酬モデル (Process Reward Model)**: 数学問題では最終答だけでなく**途中の解法過程**を評価したい場合があります。[Math-Shepherd]()は各ステップに報酬スコアを与える**逐次的な評価モデル**で、連立方程式の各変形や証明の各推論ステップごとに「正しい一歩か否か」を判定するものです。このモデルは**人手のアノテーション無し**で自動構築され、まず既存の問題解答の各ステップを検証してスコア付けし、それを用いて**逐次ステップごとのPPO**で言語モデルを強化学習させました。その結果、例えばMistral-7Bモデルの数学性能がGSM8K（小学生～中学生向け数学データセット）で77.9%→84.1%、MATH（数学コンペ問題データセット）で28.6%→33.0%と大幅に向上し、さらに生成解答を多数リランクする「検証モード」でそれぞれ89.1%、43.5%にまで精度向上しています。これはGPT-4に匹敵する水準の正答率です。

- **グループ相対方策最適化 (GRPO)**: こちらはDeepSeekが提案した強化学習アルゴリズムPPOの変種です([DS-Math]())。ポイントは**一組の出力をまとめて評価**し、**相対的な良さ**に基づいてポリシーを更新することで、**価値ネットワーク（critic）を不要化**した点です。GRPOではニューラルネットの報酬モデルを使わず、一群の生成結果に対して例えば「証明が完了したか」「形式エラーがないか」など**ルールベースの評価関数**でスコアを与え、それらの相対差分のみで勾配を計算します。DeepSeek-R1でも重要技術として採用され、従来のPPOと比べ安定性と効率が向上したとされています。

### モンテカルロ木探索 (MCTS) と検索強化
チェスや囲碁のAIで有名な **モンテカルロ木探索 (Monte Carlo Tree Search)** も、数学や証明の文脈で重要な役割を果たします。証明探索では、一度の生成で証明全体を生成することは困難なため、**部分的な証明を何度も試行**して解に辿り着くことが求められます。MCTSは確率的に**多数の経路を探索しつつ、有望な経路に徐々に集中**する手法で、AlphaZeroではこれを自己対戦に組み込んで方策を洗練させました。定理証明でも、HyperTree Proof SearchはAlphaZeroにヒントを得た**HyperTree探索アルゴリズム**を導入し、Metamathにおける定理証明の成功率を従来の56.5%から65.4%へ、さらにオンライン学習込みで82.6%まで引き上げました。

MCTSは特に**逐次ステップ**で証明を組み立てるタイプのシステムで威力を発揮します。Microsoftの**rStar-Math**は7B規模という小型モデルながら、MCTSを用いて**試行的に思考連鎖を探索**し、逐次解答を精錬する「システム2的」アプローチで性能を飛躍的に伸ばしました ([rStar-Math]())。rStarではモデルが自然言語による推論とPythonコードによる計算を組み合わせたステップを生成し、それらをMCTSで分岐展開しながら成功率を高めています。その結果、**AIME**（米国数学コンテスト上位レベル）で53.3%正解（人間のトップ20%水準）を達成し、MATHベンチマークでも7Bモデルにして正答率90.0%という驚異的成果を報告しています。またDeepSeek-Prover-V1.5でも**RMaxTS**という独自変種のMCTSを導入し、内在的報酬による多様な証明経路探索で性能向上を図っています([DS-Prover]())。

### その他の学習戦略
上記以外にも、**自己教師あり学習**の工夫として**自己評価 (self-verification)**や**思考連鎖 (chain-of-thought)**が用いられています。Lean-STaRは各証明ステップの前にモデルが**非形式的な思考テキスト**を生成するよう訓練し、この思考過程を経てタクティクスを出力させることで証明成功率を上げました ([Lean-STaR]())。このように**一旦モデル自身に理由付けさせる**ことで、行き当たりばったりのステップ生成を防ぎ、全体の一貫性を保つ効果があります。また**自己対話形式**で証明を進める[Self-Taught Reasoner]()や、モデル自身が問題を生成・解決して学習データを拡充するアプローチ（OpenAIの[自己練習]()、Microsoftの[Phi]()シリーズなど）も研究されています。こうした多様な手法の組み合わせが、現在の最先端モデルの高性能を支えています。

## 主要な自動証明AIシステムの比較

近年発表された主要なAIシステムやモデルを、大きく **非形式数学（自然言語）** と **形式数学（証明支援系）** に分けて紹介します。それぞれのアプローチと特長、技術的ポイントを整理します。

### 非形式数学問題を解く大規模言語モデル群
- **ChatGPTシリーズ（GPT-4など）**: OpenAIのGPT-4は多分野に汎用的な対話型LLMですが、数学分野でも卓越した性能を示しています。GPT-4は明示的なツールなしで高度な計算や論証を行い、米国高校レベルの数学コンテストで人間の成績を上回るスコアを記録しました([?]())。これらは**チェイン・オブ・ソート(CoT)**による段階的推論や**自己評価**を取り入れたプロンプト設計、そしてRLHFによる解答の一貫性向上によって達成されています。例えば[Sparks of AGI]()ではGPT-4がAMC12（高校数学）で90%以上の正答率を示したと報告されています。また、ChatGPTはリアルタイムで対話しながら証明の議論ができ、Leanなど外部定理証明器と連携するプラグイン([LeanDojo]())も開発されており、**汎用モデルを専門タスクに応用**する研究があります。

- **Claude（Anthropic）**: ClaudeはAnthropic社のLLMで、RLHFをさらに発展させた **憲法AI（constitutional -）** によるフィードバック調整で知られます。数学専用ではありませんが、大規模データで学習されているため複雑な数学パズルにも対応可能です。実際、ClaudeはGoedel-Proverにおいて **数学定理の自動形式化（auto-formalization）** に活用されました。Claude 3.5（通称Claude-Sonnet-3.5）は難解な定理の形式化ペアを数多く生成し、形式データ不足を補うのに寄与しています。このように**汎用LLMを専門データ生成に使う**のも有効な戦略です。

- **PaLM 及び Minerva（Google）**: 2022年にGoogleが発表したMinervaは、5400億パラメータのPaLMモデルを科学・数学領域のコーパスで追加学習した特化モデルです ([Minerva]())。Minervaは微調整と推論時の工夫（few-shotプロンプトや複数解答の投票など）により、高度な数式問題を解く能力を獲得しました。たとえばMATHデータセットで**約50%**の正解率を記録し、これはそれ以前のGPT-3系モデルを大きく凌駕する結果でした。またMinervaは計算過程を詳述する解答を生成し、**ソリューションの透明性**が高いことも評価されます。
<!-- 後継のPaLM 2ベースのモデル（コードネームGemini）は未発売ながらマルチモーダル機能も持つと噂され、図形問題など**視覚情報を含む数学問題**への適用が期待されています。 -->

- **LlamaおよびLlemma（メタ/EleutherAI）**: Meta社のLlamaシリーズはオープンソースな大規模モデルとして公開され、数学特化モデルの基盤となりました。その代表例が**Llemma**です ([Llemma]()))。LlemmaはCode Llamaを初期モデルとし、数学論文やウェブ上の数式含むデータ、証明対話などを集めた**Proof-Pile-2**コーパスで追加学習して得られた7B/34Bパラメータのモデルです。その性能はMATHベンチマークで同規模のMinervaを上回り、既知のオープンモデル中トップクラスでした。さらに、驚くべきことにLlemmaは**電卓など外部ツールを明示的に組み込んでいない**にもかかわらず、多段の計算や定理証明支援系Leanでの定理証明まで（追加fine-tune無しで）こなせる汎用性を示しています。これは大規模事前学習データに数学情報が潤沢に含まれている効果と考えられ、OSSコミュニティにおける数学AI研究を推進するモデルとなりました。

- **Qwenシリーズ（Alibaba）**: QwenはAlibabaが開発したLLMで、多言語・コード・数学など多方面に特化モデルを展開しています。特に**Qwen-2.5-Math-72B**は72億パラメータの大規模モデルで、数学問題に専門特化したバージョンです([Qwen2.5-Math]())。Qwen2.5-Mathでは**専用の報酬モデル（72B!）**まで用意し、自己対話形式で証明を探索・評価してモデルを調整しています ([Qwen2.5-Math-PRM-72B](https://arxiv.org/abs/2501.07301))。 ([DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437v1))によれば、Qwen2.5-Math-72BはAIMEやMATHでそれ以前のベストモデル（おそらくMinervaやGPT-4相当）を**約10%**上回るスコアを達成し、一時オープン系で世界最高性能でした。例えばMATHでは約80%に迫る正答率、AMC12でも高得点だったと報告されています。その後登場したDeepSeek-V3にこそ抜かれたものの、Qwenは**18兆トークン**という巨大全文コーパスで事前学習されており、中国語を含む多言語対応と知識量で優れています。

- **DeepSeek-V3**: 2024年末に公開された**DeepSeek-V3**は、Mixture-of-Experts (MoE) 構造を持つ**6710億パラメータ**の超大規模モデルです([DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437v1))。14.8兆トークンで事前学習され、DeepSeek-R1からの蒸留も取り入れてチューニングされた結果、各種ベンチマークでオープンモデル最強を誇ります。特に数学分野では、MATH-500テストで**90.2%**という前例のない正答率をマークし、従来トップのQwen2.5-72Bを10ポイント以上引き離しました。この性能は一部の**クローズドソースモデル（GPT-4等）をも凌駕**するとされます。DeepSeek-V3成功の要因には、DeepSeek独自の**知識蒸留**（大規模RL強化したDeepSeek-R1から小型モデルへ推論パターンを継承）や、大規模分散学習技術（FP8精度訓練）が挙げられます。もっとも、膨大な計算資源が必要なため誰もが真似できる手法ではありませんが、「巨大モデルで数学問題はかなり解決できる」ことを示した点で意義深いです。

- **rStar-Math（Microsoft）**: 前述のとおり、Microsoft Research AsiaのrStar-Mathは「**小さなモデルを工夫で賢くする**」戦略の好例です ([rStar-Math]())。7Bという桁違いに小さいモデル（Qwen2.5-Math-7B）を起点に、MCTSを組み込んだ**自己進化**を4ラウンド行い、難問を解くための方策とプロセス評価モデルを洗練させていきました。その結果、MATH正答率58.8%→90.0%、AIME正答率53.3%に達し、OpenAIの開発中モデル（o1-previewと称されるGPT-4系統モデル）を凌駕したと報告されています。注目すべきは、**チェインオブソートをPythonコード付きで出力させた**点です。モデルに推論過程を自然文＋コードで書かせ、コード実行で検算しながら学習を進めています。これにより、小型モデルでもバグなく計算を行い、一貫した論理展開を習得できました。rStarは「巨大化一辺倒ではない効率的AI」の可能性を示し、今後の小型専門モデル開発に影響を与えています。

- **Math-Shepherd**: こちらも既出ですが、Mistral-7Bなどオープンソースモデルを**自動評価付き強化学習**で鍛え上げた成果です ([Math-Shepherd]())。Math-Shepherdは**逐次ステップの正しさ**を判定する報酬モデルを自動構築し（各ステップをルールベース検証）、それでモデルをPPO訓練しました。最終的にMistral-7BがMATHで33.0%（従来28.6%）と向上し、また複数解答を生成してMath-Shepherdで良否を判定・選択することで43.5%にまで精度が上がっています。これはMinerva 62Bの記録に匹敵し、**データの工夫で小型モデルを飛躍させた**例です。Math-Shepherd方式は人手による細かなフィードバックなしで済むため、今後さまざまな推論タスクへの応用が期待されます。

### 形式的定理証明へのAI応用モデル群
- **GPT-f（OpenAI）**: 形式的定理証明への大規模言語モデル適用の先駆けがGPT-fです([GPT-f]())。GPT-fはGPT-3を基に、Metamathという形式証明言語の定理集合を用いて微調整されました。Metamathでは論理式を逐次演繹していきますが、GPT-fはこの**次の一手**を生成する役割を担います。興味深いことに、従来の自動定理証明器が既存定理の組合せ探索に終始するのに対し、GPT-fは**新しい補題となる式**自体を生成できる点です。これは人間が証明で見せる創造性に近く、実際GPT-fはMetamathライブラリにない**新証明**を発見し、それが公式に受理されました。これは深層学習システムが初めて**数学の定理ライブラリに貢献した**例として注目されました。GPT-fは探索アルゴリズムとしては単純なランダムゆらぎ付き逐次生成＋バックトラッキングでしたが、Transformerの柔軟な生成力が証明探索に有効であることを示しました。

- **HyperTree Proof Search（Meta）**: Facebook/MetaのLampleらは、AlphaZero型の強化学習を定理証明に取り入れた**HyperTree Proof Search (HTPS)**を開発しました ([HTPS]())。HTPSは証明木をゲーム木に見立て、ニューラルネットによる方策（次の証明ステップ予測）と価値（現状から証明完了まで行ける確率予測）を訓練しつつ、木探索で見つけた新証明をオンラインで学習するループを回します。Metamath環境で行った実験では、教師あり学習だけのモデルが未証明だった定理の65.4%を証明でき、さらにオンライン学習を重ねると82.6%まで解けるようになりました。またLeanの定理問題セット（miniF2Fカリキュラム）でも従来31%→42%に向上しています。この手法のポイントは、**証明探索と学習を一体化**してモデルを自己強化する点です。大規模データで事前学習したLLMとは異なり、環境内でモデルが試行錯誤して成長する様子は強化学習らしいアプローチです。

- **Lean-STaR（CMU/NYU）**: Lean-STaRは2025年発表の最新手法で、**Lean定理証明に思考連鎖を組み込んだ学習**フレームワークです ([Lean-STaR]())。Leanは証明支援系であり、人手でタクティクスを記述して証明します。Lean-STaRでは、各タクティクス適用前にモデルに **「非形式的思考」文** を生成させます。これは「次に何を証明すべきか」「どの補題を使うべきか」といった人間の頭の中の考えをテキスト化したもので、訓練時には既存の完成した証明から逆算してこの思考文を合成し、モデルに学習させました。推論時にはモデル自身が考えを文章で出力し、それに従う形でタクティクスを提案します。この**Think step → Prove step**のインタリーブにより、純粋にタクティクスのみを予測するよりもうまく次手を選べるようになり、結果としてLean証明問題のPass@64成功率が43.4%から46.3%へ改善しました。向上幅自体は数ポイントですが、**証明過程の潜在情報**をモデルに与えることで性能が上がることを示した意義は大きいです。Lean-STaRはさらにExpert Iteration（自己強化学習）も組み合わせており、人手ラベルなしで追加改善も果たしています。

- **LeanDojo & ReProver**: **LeanDojo**はLean向けのオープンソース**統合フレームワーク**で、データ抽出から相互作用環境まで提供します ([LeanDojo]())。Leanの数学ライブラリ(mathlib)から約10万定理・約20万タクティクスのデータセットを構築し、特に**前提（premise）情報**を各ステップにタグ付けしているのが特徴です。これは「どの前提を使うか」の選択（**前提選択（premise selection）**）が自動証明のボトルネックであることに対応した工夫です。LeanDojoはまた、LeanをGym風の強化学習環境として操作できるAPIも提供し、LLMが対話的にLeanに証明指示を送ることを可能にしています。これを使い、ChatGPTプラグインを作成して対話的に定理証明させるデモも公開されています。

LeanDojoを用いて開発された**ReProver**は、Encoder-Decoder型Transformerに**過去の定理（Premise）を検索して付与**する検索強化（retrieval-augmentation）方式で次のタクティクスを生成します。このモデルはLeanDojoベンチマーク上で、従来の単純モデルやGPT-4ゼロショットを上回る証明成功率を示しました。特に難度の高い``novel_premises''分割（訓練時に見たことのない補題が必要な定理）で顕著に優れ、既存の自動タクティクス（tidyタクティクス）より多くの定理を証明しています。さらにReProverは、miniF2FやProofNetといったベンチマーク定理にも挑戦し、**Leanで未解決だった定理に新証明を発見**することに成功しました。具体的にはminiF2Fで33問、ProofNetで39問の定理を解き、その過程でProofNet側の形式化ミスも複数見つけ出したとのことです。LeanDojo/ReProverの成果は、**既存定理の有効活用**と**環境との相互作用**がカギであり、今後のRLや検索との併用による更なる改良が期待されます。

- **DeepSeek-Prover シリーズ**: DeepSeekは前述の汎用LLMシリーズだけでなく、Lean形式の定理証明専用モデルも開発しています([DS-Prover]())。DeepSeek-Prover-V1.5はLean4対応のオープンモデルで、DeepSeekMath-Base（汎用数理事前学習モデル）を初期化に用い、独自に生成した形式証明データでSFTを行った後、**証明支援系からのフィードバックを用いた強化学習 (RLPAF)** を施しています。RLPAFではLeanで証明を試行し、成功すれば報酬、失敗すればペナルティを与えてモデルを更新するもので、いわばRLHFの人間評価を**証明支援系の自動検証結果**に置き換えた手法です。さらにDeepSeek-Prover-V1.5は**RMaxTS**と呼ぶMonteCarlo Tree Searchを導入し、一度に証明全体を構築するのではなく部分的に探索を広げながら証明を完成させています。これらの工夫により、ベンチマークであるminiF2F（高校数学レベル）で**63.5%**、ProofNet（学部数学レベル）で**25.3%**という当時の最先端スコアを達成しました。特にminiF2Fの63.5%は、それ以前のLeanモデル（HyperTree時の42%など）を大きく引き離すものでした。

<!-- DeepSeekはその後も改良を続けており、最新バージョンと目される**DeepSeek-Prover-V3**については詳細不明ながらさらなる性能向上が予想されています（DeepSeek開発元のブログでは、今後Lean定理証明での新記録が示唆されています）。 -->

- **Goedel-Prover**: 2025年初頭に論文公開された**Goedel-Prover**は、名前が示す通り「ゲーデル」を冠した野心的プロジェクトです ([Goedel Prover]())。これはオープンソースのLLMで、Lean形式の証明自動化においてSOTA性能を達成したと報告されています。Goedel-Proverの特徴は、**非形式→形式のデータ拡張**に力を入れた点です。Leanの公開定理データ（Lean WorkbookやMathlib4）だけでは証明付き定理がごく数万と少ないため、彼らはまずNuminaMathやAoPS等の大量の自然言語数学問題を**Lean定義に自動翻訳**しました。この翻訳器として、Leanコミュニティが整備した並列コーパス（Lean Workbook）で訓練したモデルや、Anthropic Claudeを使って得た追加対訳を駆使し、数十万規模の定理をLean形式で生成しています。次に、その自動形式化した問題を定理証明器で解かせて証明ペアを得ようと試みました。その際に自前のモデルも参加させ、**自己教師ありでWhole-proof生成**（証明全体を一括生成）を学習させました。Goedel-Proverはこのように準備したデータでSFTされており、結果としてminiF2Fテストで**57.6% (Pass@32)**を達成、DeepSeek-Prover-V1.5を7.6ポイント上回りました。またPutnamレベルの難問を含む**PutnamBench**で512回生成中7問解け（順位表1位）、Lean Workbook大量の定理も解くことに成功しています。特筆すべきは、Goedel-Proverは**逐次対話型でなく、一度に証明全文を生成**する方式を採用している点です。これは一見ハードルが高いですが、モデルが十分賢ければ**探索なしで証明を書き下せる**という可能性を示しています。もっとも、まだPass@Nで評価すると多く試行が必要な段階であり、今後はLean-STaRのような逐次ステップとのハイブリッドも検討されるでしょう。

- **Thor**: ThorはNeurIPS 2022で報告された、言語モデルと自動推論システムを統合するフレームワークです ([Thor]())。「ハンマーを振るう」という名の通り、既存の自動定理証明器（ATPs、例えばE-prover）の力を借りる形でLLMを用います。具体的には、まず言語モデルが**有用な補題や前提を選択（premise selection）**し、次にそれを入力として自動定理証明器が機械的に証明を試みます。この2段構えにより、言語モデル単独では難しい厳密な探索を古典的手法で補完しつつ、巨大検索空間から有望部分をLLMが絞り込む効果があります。ThorはIsabelle/HOL環境で評価され、**与えられた定理の約57%を自動証明**できたと報告されています。さらに上位システムとしてBaldurを組み合わせることで難度の高い定理も解けるようになるなど、**LLM＋ATPの協調**に新境地を開きました。

- **Draft, Sketch and Prove (DSP)**: Meta AIのDSPは、**非形式的な証明文を書き、それをもとに形式証明を探索**するという三段構えのアプローチです ([DSP]())。まずLLM（Minerva 540Bなど使用）に与えられた定理を証明する**ドラフト（非形式証明案）**を書かせます。次に、そのドラフトから**スケッチ（形式的証明骨子）**を自動抽出します。例えばドラフト中の「〜より明らか」という記述から対応する証明ステップをIsabelleのタクティクに翻訳します。そして最後に、そのスケッチを埋める形でIsabelleの自動証明手法（sledgehammer等）を走らせ、証明を完成させます。DSPの狙いは、**人間が書いた教科書的証明**の情報を最大限形式証明に活かすことで、従来解けなかった定理も解決に導くことです。実験では、ProofWikiやMizarの人力証明をドラフトとして与えた場合に大きな性能向上が見られ、Minerva生成のドラフトでも一定の効果が確認されました。このように**非形式と形式の橋渡し**をする研究も進んでおり、長大な人間の証明を機械検証する、といった将来像につながっています。

- **Self-play LLM Theorem Provers (STP)**: STPは、従来の一括生成型の証明アプローチとは異なり、**自己対戦（self-play）**の枠組みを導入して、言語モデルが反復的に仮説（conjecture）を生成し、その仮説を証明支援系で検証・修正するという方式です([STP]())。具体的な特徴は以下の通りです。**反復的仮説生成と検証のループ** まずLLMが与えられた定理の一部あるいは補題候補を生成します。これを証明支援系（例えばLeanやCoqなど）に投入し、形式的な証明の一歩として採用できるかを検証します。もし生成された仮説が形式的に正しい場合、その情報は次の証明ステップに反映され、さらに高度な補題や証明の枝が展開されます。逆に、誤りが検出された場合は、モデルはフィードバックを受けて新たな仮説を生成するというサイクルを繰り返します。**自己対戦による探索空間の絞り込み** この反復プロセスは、まるで自分自身と対戦するかのように、試行錯誤を重ねながら最適な証明戦略を見つけ出す仕組みです。従来の「一発生成」型の方式では、一度の出力で完全な証明を得ることが難しかったのに対し、STPは途中で得られた部分的な正解を積み重ねることで、最終的な証明の一貫性や正確性を向上させています。**証明支援系との統合による堅牢性** 言語モデルが生成する非形式的な証明案を、そのまま採用するのではなく、形式検証器が各ステップごとに正当性をチェックすることで、論理的飛躍や省略のリスクを低減します。これにより、生成された証明が実際に数学的厳密性を備えているかどうかを確実に保証できる点が大きな利点です。このように、STPはLLMの生成能力と証明支援系の厳密な検証機能を組み合わせ、反復的な自己改善プロセスを通じて証明探索の効率と正確性を高める手法として注目されています。

- **LEGO-Prover**: これは、**ニューラルネットワークによる定理証明**と、証明過程で自動的に**補題ライブラリを拡張**していく仕組みを統合した手法です([LEGO]())。主な特徴は以下のとおりです。**動的な補題ライブラリの成長** 従来の証明支援系では、証明のための補題や前提知識があらかじめ定義されたライブラリに依存していました。LEGO-Proverは、証明の過程で新たな補題や中間定理を自動的に発見し、これらをライブラリに追加していくことで、次第により豊富な知識ベースを構築していきます。これにより、未知の定理に対しても、既存の補題を再利用できる環境が整い、証明探索の効率が向上します。**ニューラルネットワークによる戦略最適化** 補題の生成だけでなく、どの補題をいつどのように利用するかという証明戦略自体も、ニューラルネットワークが学習して最適化します。つまり、ライブラリの成長とともに、証明探索のアルゴリズムがその都度最適な戦略を取るようになるため、従来の固定的な手法よりも柔軟性が高まります。**長期的な自己強化学習の枠組み** LEGO-Proverは、初期の段階では単純な定理の証明から始まり、そこから有用な補題を次々と生成・蓄積することで、システム全体が段階的に高度な証明能力を獲得していくという、いわば「成長する定理証明機械」として設計されています。動的にライブラリを拡大するプロセスは、自己教師あり学習や強化学習の枠組みとも親和性が高く、将来的にはより複雑な数学体系全体に対するアプローチへと発展する可能性を秘めています。LEGO-Proverは、証明支援系の機能を活用しつつ、ニューラルネットワークの生成力と自己改善機能を組み合わせることで、従来の手法に比べてより高い柔軟性と拡張性を実現しており、今後の自動定理証明の新たな方向性として期待されています。

<!-- - **STP**は、反復的な仮説生成と自己対戦を通じて証明過程を改善する方式で、動的な「試行錯誤」により部分的な正解を積み重ねることで、複雑な証明に対しても堅牢な解法を提供します。  
- 一方、**LEGO-Prover**は、補題ライブラリの「成長」を核とし、学習済みの知識を動的に拡充することで、未知の問題にも柔軟に対処できる体制を整えています。 -->



- **Alphaシリーズ**: Google DeepMindのAlphaシリーズは、伝統的な定理証明の枠組みと最新の機械学習手法（特に自己対戦・強化学習やツリ―探索）を融合させることで、難解な数学問題に対する新たなアプローチを実現しています。以下、各手法の概要を示します。

- **AlphaProof**: AlphaProofは、IMO（国際数学オリンピック）レベルの数学問題に挑戦するために設計されたシステムです。従来の定理証明手法と同様、証明支援系（例：LeanやIsabelle）との連携を前提としつつ、自己対戦（self-play）の枠組みで証明探索を行います。**強化学習＋ツリー探索**: AlphaProofは、AlphaZeroに類似したモンテカルロ木探索（MCTS）とニューラルネットワークによる評価・方策予測を組み合わせ、証明探索空間を効果的に絞り込みます。**自己対戦による改善**: システムは、初期に生成した部分的証明や補題を元に自己対戦（self-play）を通して試行錯誤し、次第により有望な証明戦略を獲得していきます。**証明支援系との連携**: LLMが生成した非形式的な証明案を、形式検証器が各ステップで正当性をチェックすることで、論理の一貫性と厳密性が保証されます。AlphaProofは、従来の探索手法では解答が得にくい難問に対して、IMO銀メダルレベルの成果を示すなど、証明探索と強化学習の融合が有効であることを実証しました。これにより、LLMの生成力だけでなく、証明の厳密性を保持しながら新たな補題や証明戦略を発見する可能性が示されています。

- **Alpha Geometry**: Alpha Geometryは、幾何学分野の問題に特化したシステムです。従来の定理証明技術と深層学習の融合を図り、幾何学的な構造や図形に関する知識を効果的に扱います。**幾何学的特徴量の表現**: 図形や空間の関係性、対称性、距離や角度などの不変量をニューラルネットワークが学習し、証明に活かします。**形式証明支援との統合**: 幾何学問題は、図形の描画や定理の補題の自動生成を通して、証明支援系に組み込まれ、形式検証を受けながら証明が構築されます。**ツリー探索と自己対戦**: Alpha Proofと同様に、MCTSなどの探索手法を取り入れ、部分的な証明案を反復的に洗練させることで、複雑な幾何問題にも対応できるよう設計されています。Alpha Geometryは、従来の自然言語や代数的手法では難しかった幾何学的直観に基づく証明を、定式的かつ厳密に導出する点で大きな進歩を示しています。Nature誌の論文にもその有効性が報告され、幾何学問題の自動解決における新たな道を切り開きました。

- **Alpha Geometry 2**: Alpha Geometry 2は、初代Alpha Geometryの成果を踏まえ、より多様な幾何学的問題やより大規模な図形データセットへの適用を可能にするための改良版です。**改良されたネットワークアーキテクチャ**: Alpha Geometry 2では、幾何学的対象の表現力を高めるための新たなエンコーダ―・デコーダ構造や、グラフニューラルネットワーク的な要素を組み込むことで、より高次の空間的関係を学習できるようになっています。**大規模自己教師あり学習**: 膨大な幾何学問題データを用いて自己教師あり学習を行い、モデルが幾何学的法則や不変量を自律的に抽出する力を強化しています。**より高度なツリー探索**: 改良された探索アルゴリズムにより、証明の分岐が膨大になる場合でも効率的に有望経路を選択でき、結果として複雑な証明の収束率が向上しています。Alpha Geometry 2は、初代に比べて多様な幾何問題への対応力と証明の正確性が大幅に向上しており、幾何学的推論の自動化における最前線技術として期待されています。これにより、形式証明支援系と連携した高度な幾何証明の自動生成がさらに現実味を帯びてきました。

  Google Alphaシリーズ（AlphaProof、Alpha Geometry、Alpha Geometry 2）は、いずれも形式証明支援系との連携を前提に、自己対戦やツリー探索、自己教師あり学習などを活用して難解な数学問題の証明を自動生成する新たなアプローチです。**AlphaProof**は、IMOレベルの問題に対して探索と強化学習の組み合わせで高精度な証明を構築し、従来の一括生成方式では到達しにくい部分的証明の積み上げによって最終解に辿り着く手法を実現しています。**Alpha Geometry**は、特に幾何学に特化し、図形や空間の不変量の学習を通じて、形式証明支援系との連携による厳密な幾何証明を実現。これをさらに拡張・改善したのがAlpha Geometry 2であり、ネットワークの改良や大規模データによる自己教師あり学習の活用がその特徴です。  

- **ProofWala**: ProofWalaは、**多言語の証明データの自動合成**とその活用を軸に、形式的な定理証明のための学習データを拡充し、ニューラル定理証明モデルを強化する手法です。**多言語データの合成**:数学論文、教科書、オンライン証明リポジトリなど、複数の自然言語に記述された証明データを統合し、形式化された証明ペア（定理とその証明）の大規模コーパスを自動的に生成します。これにより、従来の単一言語・単一形式に依存しない、多様な証明データを利用できるようになります。**自動形式化と対訳生成**:ProofWalaは、自然言語で記述された証明を自動で形式的な表現（例：LeanやCoq形式）に変換する仕組みを組み込み、さらにその逆変換も行います。これにより、各言語間の情報を橋渡しし、モデルが複数の文脈から証明の共通パターンを学習できるようになります。**ニューラル定理証明モデルの訓練**:合成された大規模多言語データを利用して、定理証明のタスクに特化したニューラルネットワークをSFT（教師ありファインチューニング）やRL（強化学習）で訓練します。特に、異なる言語表現から得られる多様な証明戦略の統合が、モデルの汎用性を大きく向上させています。ProofWalaは、従来の証明データセットが抱える規模の制限や単一言語依存の問題を克服するアプローチとして注目されます。多言語データによる学習により、さまざまな数学的概念や証明技法の共通パターンがモデルに学習され、結果として異なる形式証明支援系への横断的応用が期待されます。さらに、形式証明と自然言語のギャップを埋めることで、将来的には数学者や論理学者がより容易にAIと協調して新たな定理を発見・検証できる環境が整うと考えられます。

  **ProofWala**は、多言語から合成される大規模証明データを活用することで、言語や表現形式の壁を越えてニューラル定理証明モデルを強化するアプローチです。これにより、形式証明支援系と自然言語記述の間の橋渡しが進み、より多様な数学的知識の統合が可能となります。

<!-- これらの手法はいずれも、従来の形式的証明支援系の厳密性と、ニューラルネットワークの生成・探索能力を融合することで、数学の最先端問題に挑む新たな道を切り開いています。今後もこうしたアプローチの発展が、数学や論理の研究のみならず、広範な自動推論システムへの応用を促進していくと期待されます。 -->

以上、主要なシステムを概観しました。それぞれの性能については次節でベンチマークデータごとに比較します。

## ベンチマークデータセットと性能比較
証明AIの性能を客観的に測るため、いくつかの**ベンチマーク問題集**が利用されています。本節では代表的なものを紹介し、前節の主要モデルがそれらでどの程度の成績を収めているか整理します。

- **miniF2F**: 証明支援系Lean上で動く高校数学レベルの定理問題集です ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=miniF2F%20%28Zheng%20et%C2%A0al,AMC%2C%20and%20the%20International%20Mathematical))。244題の検証用・244題のテスト用問題があり、AMC12、AIME、IMOなど数学コンテスト由来の問題をLean形式に定式化しています ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=miniF2F%20%28Zheng%20et%C2%A0al,AMC%2C%20and%20the%20International%20Mathematical))。証明難易度は高く、元々は人手で解かれていなかった問題も含みます。2022年頃の従来SOTAはHyperTreeの42% (Lean miniF2F-curriculum)でした ([HyperTree Proof Search for Neural Theorem Proving | OpenReview](https://openreview.net/forum?id=J4pX8Q8cxHH#:~:text=particular%2C%20we%20show%20that%20with,proving%20accuracy))が、DeepSeek-Prover-V1.5が**63.5%** ([[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/abs/2408.08152#:~:text=Monte,3))、Goedel-Proverが**57.6% (Pass@32)** ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=whole,K%20formal%20proofs%20for%20Lean))、Lean-STaRはPass@64で**46.3%** ([Lean-STaR: Learning to Interleave Thinking and Proving | OpenReview](https://openreview.net/forum?id=SOWZ59UyNc#:~:text=step.%20Building%20on%20the%20self,providing%20insights%20into%20their%20effectiveness))といった値を達成しています。最新ではGoedel-ProverがDeepSeekを抜き去りオープンモデル最高となりました ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=The%20performance%20on%20miniF2F%20is,RL%E2%80%99s%20Pass%403200%20by%202.7))。

- **ProofNet**: アリゾナ大らが提唱した、**学部数学レベル**の定理集です ([zhangir-azerbayev/ProofNet: Benchmark for undergraduate ... - GitHub](https://github.com/zhangir-azerbayev/ProofNet#:~:text=GitHub%20github,benchmarks%20consists%20of%20371%20examples))。371問の自然文定理と、それに対応するLean定理がペアになっています ([zhangir-azerbayev/ProofNet: Benchmark for undergraduate ... - GitHub](https://github.com/zhangir-azerbayev/ProofNet#:~:text=GitHub%20github,benchmarks%20consists%20of%20371%20examples))。内容は有名な教科書や問題集（Artinの代数やRudinの解析など）から取られており、大学数学の広範な範囲を含みます。ProofNetは**自動形式化と自動証明**の二つの課題に使われます。すなわち、自然文の定理文を正確にLeanに落とし込むこと（Autoformalization）と、そのLean定理を無人で証明すること（Formal proving）です。ProofNetに対しては、ProofGPTというGPT-3ベースモデルで半自動形式化した成果 ([ProofNet: Autoformalizing and Formally Proving Undergraduate ...](https://openreview.net/forum?id=qkhpbRNSSE#:~:text=ProofNet%3A%20Autoformalizing%20and%20Formally%20Proving,Pile%20that%20these))や、LeanDojoのReProverが**39問解決**した事例 ([LeanDojo: Theorem Proving with Retrieval-Augmented Language Models](https://leandojo.org/#:~:text=Discovering%20New%20Proofs%20and%20Uncovering,Formalization%20Bugs))などがあります。DeepSeek-Prover-V1.5はProofNetで**25.3%**を達成し当時SOTAでした ([[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/abs/2408.08152#:~:text=Monte,3))が、Goedel-Proverはさらなる改良を図っているようです（具体値は未公開ですが、miniF2F同様更新した可能性があります）。

- **MATH**: ハードな数学文章題（数学コンペ問題）を集めた大規模データセットで、Hendrycksらが2021年に公開しました。AMC12、AIME、USAMOなど米国の数学コンテスト問題約12,500問を含み、問題文と正解をペアにしています。証明ではなく最終答を答える形式ですが、多くは記述式で途中計算や証明が必要です。モデルの**定量的推論**能力を測る標準ベンチマークとして定着しており、MinervaやChatGPT系列もこのデータで評価されます。Minerva(540B)が**50.3%**正解 ([DeepSeek-V3 Technical Report](https://arxiv.org/html/2412.19437v1?ref=platformer.news#:~:text=On%20math%20benchmarks%2C%20DeepSeek,like%20models))、GPT-4が約45%前後と推定され、Qwen2.5-72Bが**約80%** ([DeepSeek-V3 Technical Report](https://arxiv.org/html/2412.19437v1?ref=platformer.news#:~:text=On%20math%20benchmarks%2C%20DeepSeek,like%20models))、DeepSeek-V3およびrStar-7Bが**90%前後** ([Microsoft's new rStar-Math technique upgrades small models to outperform OpenAI's o1-preview at math problems | VentureBeat](https://venturebeat.com/ai/microsofts-new-rstar-math-technique-upgrades-small-models-to-outperform-openais-o1-preview-at-math-problems/#:~:text=After%20four%20rounds%20of%20self,Math%20achieved%20significant%20milestones))という進歩を遂げています。この飛躍的向上は、多試行(多数の解答案を生成してベストを選ぶ)や高性能モデルの登場によります。なお、Math-Shepherd版Mistral7Bはシングル解答で33%、自己検証込みで**43.5%**でした ([[2312.08935] Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://arxiv.org/abs/2312.08935#:~:text=employed%20to%20reinforce%20LLMs%20with,the%20future%20evolution%20of%20LLMs))。

- **Putnam**: プットナム数学競技会は全米トップレベルの大学数学コンテストで、問題は非常に難解です。AI研究でも、Putnam問題を解ければ人間専門家レベルと言えます。2023年にOpenAIがGPT-4で過去問に挑戦した非公式結果では、満点120点中約80点程度という報告もあります（ただし問題文を分割して与えるなどサポートあり）。形式的には、Goedel-Proverが**PutnamBench**と称するセットで512試行中7問解決 ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=whole,K%20formal%20proofs%20for%20Lean))とありますが、このベンチマーク詳細は今後明らかになるでしょう。現状では、Putnam問題を安定して解けるAIは存在しないと見てよく、今後の目標とされています。

- **その他のデータセット**: 汎用的な算数・数学として**GSM8K**（小学生～中学生レベルの文章題8000問）があります。これはChatGPTやMath-Shepherdの評価によく使われ、GPT-4やMath-Shepherd強化版で90%以上正解とほぼ人間に迫る領域になりました ([[2312.08935] Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://arxiv.org/abs/2312.08935#:~:text=employed%20to%20reinforce%20LLMs%20with,the%20future%20evolution%20of%20LLMs))。また英・中の数学試験集である**A-level / 高考 (GaoKao)**問題集、IMDBやAIcrowdの**数独/パズル**系データなどもモデルの論理推論力評価に使われています。形式系ではLeanの**数学ライブラリmathlib**を利用したスプリット（LeanDojoのrandom/novel分割）や、Coq/Isabelleの定理集による評価も行われています。

以上のベンチマークによる比較を、表形式にまとめます。

## 技術的比較と考察
最後に、各アプローチの**性能や性質の違い**を技術的観点から考察します。

**モデル規模と推論アルゴリズム**: 大規模モデルは一般に知識量とパターン認識能力が高く、MinervaやGPT-4、DeepSeek-V3のように**スケールで殴る**戦略は高い性能をもたらしました。しかし、それだけでは解けない問題に対して、探索アルゴリズムや自己検証を組み合わせたrStarやHyperTreeのアプローチが有効であることも示されました。小型モデルであってもMCTSで多数の試行ができれば、結果的に大モデル並みの網羅性を持てます。一方、Goedel-Proverのように大型モデル＋探索で性能を底上げするケースもあり、**「大きさ × 賢い探索」の両輪**が重要です。

**外部ツール・計算資源の統合**: 数学問題ではしばしば数値計算や代数操作が必要ですが、LLM単独では誤りもあります。rStarがPythonコードを用いて計算検証したように、今後はモデルが自分でCAS（Computer Algebra System）や数式ソルバーを呼び出すことが増えるでしょう。既にToolformer的なアプローチで計算器や定理DBへのアクセスを組み込む試みがあります。また、証明の正当性保証には形式検証器との連携が不可欠です。ThorやLeanDojoのように、モデルの提案をATPや証明支援系がチェックする構造は、**誤答を原理的に排除**できる強みがあります。一方で、それらとの対話が過度に増えると効率が落ちるため、Goedel-Proverのように**一発で正しい証明を出力する能力**も追求されています。

**逐次ステップ vs 全体生成**: 証明をステップバイステップで構築する方法はデバッグしやすく、人間の思考にも対応します。Lean-STaRやDeepSeek-Prover、LeanDojoはこの方式で一歩ずつ進めていきます。逐次型では途中で間違えても巻き戻したり方針転換したりできますが、探索コストが高い欠点があります。逆にGoedel-Proverのようなホールプルーフ一括生成は、一度の生成で失敗すればアウトですが、LLMの**文脈保持力**を最大限活かせる利点があります。どちらが優れるかはタスクによりますが、現在は**ハイブリッド**が最有力でしょう。例えば、まずモデルに大雑把な証明アウトラインを書かせ（Draft/Sketch）、それをガイドに詳細証明を機械探索する、といった流れです。

**RLHFと安全性・スタイル**: 証明AIも、人間と対話する場面では答の**わかりやすさ**や**論理の飛躍の無さ**が重要です。ChatGPT系がRLHFで整合的な説明を行えるのは数学解説にも有用です。ただし、RLHFで重視される「ユーザの好み」と「数学的厳密さ」は必ずしも両立しません。正確だが冗長な証明 vs 簡潔だが穴のある証明、どちらを良しとするかは文脈次第です。そのため、Math-Shepherdのように**人ではなく論理規則がフィードバックする**仕組みや、Constitutional AIであらかじめ「数学では厳密性を優先」など原則を定めるやり方が模索されています。今後は、証明の評価関数自体を高度化し、正確さ・明晰さ・簡潔さといった多次元でモデルを最適化する研究も進むでしょう。

**オープン vs クローズド**: 現状、最高性能の座は非公開モデル（GPT-4など）かもしれませんが、オープン陣営の追い上げは凄まじいです。LlemmaやGoedel-Proverなどコミュニティ主導のモデルが次々と生まれ、DeepSeekやQwenのような企業オープンモデルも登場しています。オープンの強みは検証可能性と連携可能性であり、例えばLeanの全定理データを使った学習や、新しいベンチマークの即時評価など機動性があります。特に数学分野は研究者コミュニティが大きいため、オープンモデルの性能向上サイクルが今後も回り続けると期待できます。

## 今後の展望
AIによる自動証明は、この数年で劇的な進歩を遂げました。今後の展望として、いくつかのポイントが挙げられます。

1. **人間の数学研究への実用貢献**: 現在のモデルは既知問題の解答には強くなりましたが、真に新しい定理発見や証明にはまだ役立っていません。将来的には、大規模モデルが数学の未解決問題の洞察を提供したり、研究者が証明を検証・補完するパートナーとなる可能性があります。そのためには、モデルが**定義や仮定の微妙な差異**を理解し、**創造的な補題**を提案できることが鍵です。GPT-fが見せたような新証明の発見を大規模に行えるなら、数学研究のスタイル自体が変わるかもしれません。

2. **マルチモーダル化**: 幾何や視覚的直観が必要な問題では、テキストだけでなく図形やグラフの情報が重要です。Geminiなど将来のモデルは画像も入力できるとされ、例えば図形問題を読み取って証明する、といったことも可能になるでしょう。また音声で数学議論を聞き取る、ホワイトボードの手書きを解析するなど、人間のコミュニケーション様式に合わせたAIも期待されます。

3. **教育・学習への応用**: 自動証明AIは数学教育にも活用できます。学生が解いた証明をチェックしてフィードバックしたり、ヒントを段階的に与えたりする**インテリジェントチュータ**として機能できます。またProofNetやminiF2Fのような問題を自動で解説付きで解くことで、誰でも高度な数学にアクセスできる教材が作れるでしょう。重要なのはAIが**間違った解説**をしない保証ですが、形式検証と自然言語説明を組み合わせることでかなり信頼度の高いチュータが実現しそうです。

4. **統一的な知識ベース**: 将来的に、AIが数学の全分野をカバーするようになると、証明検索だけでなく**知識の統合**が課題になります。ProofWikiや数学の教科書など様々な知識源をモデルが吸収し、それらをまたがった証明を組み立てることが理想です。カテゴリ論や解析学など異分野の知識が結びつく証明も、人間のひらめきではあり得ることです。AIが大量の知識を関連付け、新概念を導入して証明する境地に達すれば、もはや「定理証明機械」というより**数学発見エージェント**となるでしょう。

5. **評価基準と信頼性**: 人間社会でAIが証明した結果を受け入れるには、透明性と信頼性が不可欠です。形式証明なら機械検証できるので正しさは保証されますが、モデルが出力した非形式証明を人間が読む場合、その論理飛躍や省略がないかチェックする必要があります。将来、AIが「この主張は明らか」と言ったときに、それを人間が確認する手間が減るよう、AI自ら**疑問箇所を細かく展開できる**ようになることが望まれます。いわば「説明責任」を果たせるAIです。技術的には、CoTをより階層化し必要に応じ詳細化する**階層型思考**や、ユーザの指示で証明の別バリエーション（例えば別解）も提示できる柔軟性などが求められます。

総じて、自動証明の分野は**シンボリックAIと統計的AIの融合**という長年の夢が具体化しつつある最前線です。論理の厳密さと学習の汎用性を両立する試みは、今後のAI研究全般にも示唆を与えるでしょう。数学という人類知の王道において、AIがどこまで創造的になれるのか、今後も注目が集まります。

## 主要モデルとベンチマークの比較表

各モデル/システムについて、その特長的手法とベンチマーク性能をまとめます。

| モデル / システム                    | アプローチの特長（学習手法・アルゴリズム）                                                                      | 主なベンチマーク性能（達成年）                                   |
| ------------------------------------ | ----------------------------------------------------------------------------------------------------------- | -------------------------------------------------------- |
| **GPT-4 (ChatGPT系列, OpenAI)**      | 1兆+パラメータ汎用対話LLM。RLHFで整合性向上。チェインオブソート活用。ツール未使用で高度推論。                      | MATH推定45%、AMC12ほぼ満点、IMO問題も一部解答（2023）        |
| **Claude 3.5 (Anthropic)**          | 1000億+規模対話LLM。憲法AIで人間嗜好最適化。長文での一貫した推論が得意。<br>※数学特化ではないが形式化データ生成に活用。 | - （Claude出力のLean定式化によりGoedelで数万定理生成 ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=problem%20statements%20in%20these%20datasets,formalize%20the%20statements%20and%20then))） |
| **Minerva (PaLM 540B, Google)**     | 5400億パラメータ。科学技術文献で追加学習し数式適応。CoT＋多数決で安定解答。                                        | MATH **50.3%** ([DeepSeek-V3 Technical Report](https://arxiv.org/html/2412.19437v1?ref=platformer.news#:~:text=On%20math%20benchmarks%2C%20DeepSeek,like%20models))、GSM8K 80.2%、AMC12 94%（2022） |
| **Llama 2 (Meta)**                  | 700億パラメータ（最大）。オープンソースLLMの基盤。数学知識も広く内包。                                             | MATH ~20%（推定、ベースモデル）                               |
| **Llemma 34B (EleutherAI)**         | CodeLlama 34Bを数学特化コーパスで200Bトークン追加学習。証明データ多数含む。<br>ツール未使用でも計算正確。             | MATH **35.9%**（Minerva 62Bの33.6%を上回り当時SOTA） ([[2310.10631] Llemma: An Open Language Model For Mathematics](https://arxiv.org/abs/2310.10631#:~:text=continue%20pretraining%20Code%20Llama%20on,code%20to%20replicate%20our%20experiments))（2023） |
| **Qwen-2.5-Math 72B (Alibaba)**     | 720億パラメータ。18兆語学習の多言語LLMを数学追加訓練。<br>**72Bの報酬モデル**で数独的推論も調整。Best-of-N最適化。    | MATH ~80%、AIME ~63%、AMC12 ~95%（2024） ([DeepSeek-V3 Technical Report](https://arxiv.org/html/2412.19437v1?ref=platformer.news#:~:text=On%20math%20benchmarks%2C%20DeepSeek,like%20models))      |
| **DeepSeek-V3 671B (DeepSeek)**     | 6710億パラメータMoE（エキスパート混合）。14.8兆語事前学習+知識蒸留。<br>RLHF類(GRPO)や自己検証も駆使。              | MATH **90.2%** ([DeepSeek-V3 Technical Report](https://arxiv.org/html/2412.19437v1?ref=platformer.news#:~:text=On%20math%20benchmarks%2C%20DeepSeek,like%20models))、AIME/AMC既知タスクでSOTA（2024） |
| **rStar-Math 7B (MSR)**             | 70億パラメータ小型モデル(Qwen派生)にMCTS自己進化×4回。<br>ステップごとにNL説明+Python計算コード併用。                 | MATH **90.0%** ([Microsoft's new rStar-Math technique upgrades small models to outperform OpenAI's o1-preview at math problems | VentureBeat](https://venturebeat.com/ai/microsofts-new-rstar-math-technique-upgrades-small-models-to-outperform-openais-o1-preview-at-math-problems/#:~:text=After%20four%20rounds%20of%20self,Math%20achieved%20significant%20milestones))、AIME 53.3%、GSM8K 88%（2025）    |
| **Math-Shepherd 7B (Peking Univ.)** | 7Bモデル(Mistral)に逐次PPO強化。**過程評価モデル(PRM)**は自動生成で人手不要 ([[2312.08935] Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://arxiv.org/abs/2312.08935#:~:text=,step%20Proximal%20Policy%20Optimization%20%28PPO))。<br>解答検証で高精度化。    | GSM8K 77.9→84.1→**89.1%**、MATH 28.6→33.0→**43.5%** ([[2312.08935] Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://arxiv.org/abs/2312.08935#:~:text=employed%20to%20reinforce%20LLMs%20with,the%20future%20evolution%20of%20LLMs))（2024） |
| **GPT-f (OpenAI)**                  | GPT-3 (13B)をMetamath形式証明でSFT。Transformerで新項導出 ([[2009.03393] Generative Language Modeling for Automated Theorem Proving](https://arxiv.org/abs/2009.03393#:~:text=automated%20theorem%20proving,by%20a%20formal%20mathematics%20community))。<br>後向き検索と結合し証明探索。               | Metamath新短縮証明を複数発見 ([[2009.03393] Generative Language Modeling for Automated Theorem Proving](https://arxiv.org/abs/2009.03393#:~:text=generation%20of%20original%20mathematical%20terms,by%20a%20formal%20mathematics%20community))（2020）                |
| **HyperTree (Meta)**               | 110億相当(推定)Transformerを**AlphaZero流オンライン強化**。 ([HyperTree Proof Search for Neural Theorem Proving | OpenReview](https://openreview.net/forum?id=J4pX8Q8cxHH#:~:text=Abstract%3A%20We%20propose%20an%20online,f.%20Online%20training))<br>MCTS系HTPSで探索しながらデータ拡張。    | Metamath **82.6%** (online学習後) ([HyperTree Proof Search for Neural Theorem Proving | OpenReview](https://openreview.net/forum?id=J4pX8Q8cxHH#:~:text=distribution,proving%20accuracy))、Lean miniF2F 42% ([HyperTree Proof Search for Neural Theorem Proving | OpenReview](https://openreview.net/forum?id=J4pX8Q8cxHH#:~:text=particular%2C%20we%20show%20that%20with,proving%20accuracy))（2022） |
| **Lean-STaR (CMU)**                | GPT-neoXベース(20B規模)をLeanタクティクでSFT。各ステップ前に**思考文生成**を学習 ([Lean-STaR: Learning to Interleave Thinking and Proving | OpenReview](https://openreview.net/forum?id=SOWZ59UyNc#:~:text=that%20is%20not%20present%20in,framework%2C%20we%20then%20apply%20expert))。<br>ExpertIterationで微調整。 | Lean定理集 Pass@64 **46.3%**（ベース43.4%） ([Lean-STaR: Learning to Interleave Thinking and Proving | OpenReview](https://openreview.net/forum?id=SOWZ59UyNc#:~:text=step.%20Building%20on%20the%20self,providing%20insights%20into%20their%20effectiveness))（2025）    |
| **LeanDojo & ReProver**            | 70億規模Encoder-Decoderに**定理検索付き**タクティク予測 ([LeanDojo: Theorem Proving with Retrieval-Augmented Language Models](https://leandojo.org/#:~:text=Bottom%3A%20Our%20ReProver%20model,to%20generate%20the%20next%20tactic))。<br>Lean環境をGym化し、Best-first検索併用。         | LeanDojoベンチ(random) 65%、(novel) 45% ＊推定（2023）<br>miniF2F新証明33問 ([LeanDojo: Theorem Proving with Retrieval-Augmented Language Models](https://leandojo.org/#:~:text=Discovering%20New%20Proofs%20and%20Uncovering,Formalization%20Bugs))、ProofNet39問 ([LeanDojo: Theorem Proving with Retrieval-Augmented Language Models](https://leandojo.org/#:~:text=Discovering%20New%20Proofs%20and%20Uncovering,Formalization%20Bugs)) |
| **DeepSeek-Prover-V1.5**           | 130億(推定)Encoder-DecoderをLean4証明SFT。RLPAFで環境報酬学習 ([[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/abs/2408.08152#:~:text=optimizing%20both%20training%20and%20inference,art))。<br>MCTS変種RMaxTSで探索強化 ([[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/abs/2408.08152#:~:text=supervised%20fine,3))。 | miniF2F **63.5%** ([[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/abs/2408.08152#:~:text=Monte,3))、ProofNet **25.3%** ([[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/abs/2408.08152#:~:text=Monte,3))（2024） |
| **Goedel-Prover**                  | 70億(推定)GPTをLean用大規模データでSFT。非形式問題を大量に**自動形式化**し学習 ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=,solving%20benchmarks)) ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=of%20math%20problems%20and%20solutions,formalize%20the%20statements%20and%20then))。<br>Whole-proof一括生成型。 | miniF2F Pass@32 **57.6%** ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=whole,K%20formal%20proofs%20for%20Lean))（DeepSeekV1.5比 +7.6%)、PutnamBench 7問/512 ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=whole,K%20formal%20proofs%20for%20Lean))（2025） |
| **Thor (Google)**                  | 既存ATP (Isabelle/Sledgehammer)＋LLM統合。 ([Thor: Wielding Hammers to Integrate Language Models and ... - arXiv](https://arxiv.org/abs/2205.10893#:~:text=arXiv%20arxiv,provers%20to%20overcome%20this%20difficulty))<br>LLMが有用補題選択、ATPが証明探索する二段階。              | Isabelle定理集 57%自動証明（2022）                             |
| **Draft-Sketch-Prove (Meta/UCL)**  | LLM(540B)で**非形式ドラフト**生成→形式スケッチ抽出→Isabelle自動証明。 ([Guiding Formal Theorem Provers with Informal Proofs - arXiv](https://arxiv.org/abs/2210.12283#:~:text=We%20introduce%20Draft%2C%20Sketch%2C%20and,to%20guide%20an%20automated%20prover))<br>ProofWiki等既存証明も活用。      | MiniF2F 既存証明ありで大幅性能向上（詳細数値不明、2023）          |

※各モデルのベンチマークは公開情報や論文から引用 ([[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/abs/2408.08152#:~:text=Monte,3)) ([DeepSeek-V3 Technical Report](https://arxiv.org/html/2412.19437v1?ref=platformer.news#:~:text=On%20math%20benchmarks%2C%20DeepSeek,like%20models)) ([Microsoft's new rStar-Math technique upgrades small models to outperform OpenAI's o1-preview at math problems | VentureBeat](https://venturebeat.com/ai/microsofts-new-rstar-math-technique-upgrades-small-models-to-outperform-openais-o1-preview-at-math-problems/#:~:text=After%20four%20rounds%20of%20self,Math%20achieved%20significant%20milestones)) ([[2312.08935] Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://arxiv.org/abs/2312.08935#:~:text=employed%20to%20reinforce%20LLMs%20with,the%20future%20evolution%20of%20LLMs)) ([Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving](https://arxiv.org/html/2502.07640v1#:~:text=whole,K%20formal%20proofs%20for%20Lean))。年は成果発表年。性能は異なる測定条件（Pass@NやBest-of-N）も混在するため参考値。

以上の表からも分かるように、現在のトップモデルはいずれも**複数の先進手法を組み合わせ**て性能を引き出しています。大規模モデル＋微調整＋強化学習＋探索＋評価モデルといった総合力で、人間専門家に迫る自動証明が現実味を帯びてきました。

今後、この分野はさらに活発化し、数学だけでなくソフトウェア検証や論理推論全般への応用も広がるでしょう。形式的な正当性と柔軟な知識運用を兼ね備えたAIは、信頼性が重視される分野でこそ価値を発揮するからです。自動証明AIの進化は、AIの能力が単なるパターンマッチから真の論理的推論へ深化していく過程でもあります。その歩みを追うことは、AIが知能の本質に近づいていく様子を見届けることにほかなりません。 ([[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search](https://arxiv.org/abs/2408.08152#:~:text=Monte,3)) ([DeepSeek-V3 Technical Report](https://arxiv.org/html/2412.19437v1?ref=platformer.news#:~:text=On%20math%20benchmarks%2C%20DeepSeek,like%20models)) ([Microsoft's new rStar-Math technique upgrades small models to outperform OpenAI's o1-preview at math problems | VentureBeat](https://venturebeat.com/ai/microsofts-new-rstar-math-technique-upgrades-small-models-to-outperform-openais-o1-preview-at-math-problems/#:~:text=After%20four%20rounds%20of%20self,Math%20achieved%20significant%20milestones)) ([[2312.08935] Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://arxiv.org/abs/2312.08935#:~:text=employed%20to%20reinforce%20LLMs%20with,the%20future%20evolution%20of%20LLMs))